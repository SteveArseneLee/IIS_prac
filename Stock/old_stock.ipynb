{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://learndataanalysis.org/source-code-download-historical-stock-data-from-yahoo-finance-using-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 10\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "print(now.year, now.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 10\n",
      "['AAPL', 'GOOG', '^GSPC']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "print(now.year, now.month)\n",
    "\n",
    "file_path = \"ticker.txt\"\n",
    "with open(file_path) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines = [line.rstrip('\\n') for line in lines]\n",
    "print(lines)\n",
    "\n",
    "ticker = []\n",
    "# period1 = int(time.mktime(datetime.datetime(now.year-5, 1, 1, 23, 59).timetuple()))\n",
    "# period2 = int(time.mktime(datetime.datetime(now.year, now.month-1, 30, 23, 59).timetuple()))\n",
    "period1 = int(time.mktime(datetime(now.year-10, 1, 1, 00, 00).timetuple()))\n",
    "period2 = int(time.mktime(datetime(now.year, now.month-1, 30, 23, 59).timetuple()))\n",
    "interval = '1d' # 1d, 1m\n",
    "\n",
    "for i in lines:\n",
    "    \n",
    "    query_string = f'https://query1.finance.yahoo.com/v7/finance/download/{i}?period1={period1}&period2={period2}&interval={interval}&events=history&includeAdjustedClose=true'\n",
    "\n",
    "    df = pd.read_csv(query_string)\n",
    "    # print(df)\n",
    "    df.to_csv(i+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://analyzingalpha.com/yfinance-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "goog = yf.Ticker('goog')\n",
    "data = goog.history()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhr = yf.Ticker('DHR')\n",
    "info = dhr.info\n",
    "info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_all_tickers import get_tickers as gt\n",
    "\n",
    "list_of_tickers = gt.get_tickers()\n",
    "# or if you want to save them to a CSV file\n",
    "gt.save_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytickersymbols import PyTickerSymbols\n",
    "\n",
    "stock_data = PyTickerSymbols()\n",
    "countries = stock_data.get_all_countries()\n",
    "indices = stock_data.get_all_indices()\n",
    "industries = stock_data.get_all_industries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(countries)\n",
    "print(indices)\n",
    "# print(industries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytickersymbols import PyTickerSymbols\n",
    "\n",
    "stock_data = PyTickerSymbols()\n",
    "# the naming conversation is get_{index_name}_{exchange_city}_{yahoo or google}_tickers\n",
    "# dax_google = stock_data.get_dax_frankfurt_google_tickers()\n",
    "dax_yahoo = stock_data.get_dax_frankfurt_yahoo_tickers()\n",
    "sp100_yahoo = stock_data.get_sp_100_nyc_yahoo_tickers()\n",
    "# sp500_google = stock_data.get_sp_500_nyc_google_tickers()\n",
    "dow_yahoo = stock_data.get_dow_jones_nyc_yahoo_tickers()\n",
    "# there are too many combination. Here is a complete list of all getters\n",
    "all_ticker_getter_names = list(filter(\n",
    "    lambda x: (\n",
    "        # x.endswith('_google_tickers') or x.endswith('_yahoo_tickers')\n",
    "        x.endswith('_yahoo_tickers')\n",
    "\n",
    "    ),\n",
    "    dir(stock_data),\n",
    "))\n",
    "print(all_ticker_getter_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOCKSYMBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stocksymbol import StockSymbol\n",
    "\n",
    "api_key = 'd7b549a4-f6aa-4255-90a1-8afc24a0e65f'\n",
    "ss = StockSymbol(api_key)\n",
    "us_index_list = [\"DJA\",\"DJI\",\"DJT\",\"DJT\",\"DJUSCL\"]\n",
    "for i in us_index_list:\n",
    "    symbol_list_dow = ss.get_symbol_list(index=i, symbols_only=True)\n",
    "    print(i, symbol_list_dow)\n",
    "\n",
    "# print(symbol_list_dow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stocksymbol import StockSymbol\n",
    "\n",
    "api_key = 'd7b549a4-f6aa-4255-90a1-8afc24a0e65f'\n",
    "ss = StockSymbol(api_key)\n",
    "\n",
    "test_index_list = [\n",
    "\"DJA\",\n",
    "\"DJI\",\n",
    "\"DJT\",\n",
    "\"DJUSCL\",\n",
    "\"DJU\",\n",
    "\"NDX\",\n",
    "\"IXIC\",\n",
    "\"IXCO\",\n",
    "\"INDS\",\n",
    "\"INSR\",\n",
    "\"OFIN\",\n",
    "\"IXTC\",\n",
    "\"TRAN\",\n",
    "\"XMI\",\n",
    "\"XAU\",\n",
    "\"HGX\",\n",
    "\"OSX\",\n",
    "\"SOX\",\n",
    "\"UTY\",\n",
    "\"OEX\",\n",
    "\"MID\",\n",
    "\"SPX\",\n",
    "\"S5TELS\",\n",
    "\"S5COND\",\n",
    "\"S5CONS\",\n",
    "\"SPN\",\n",
    "\"SPF\",\n",
    "\"S5HLTH\",\n",
    "\"S5INDU\",\n",
    "\"S5INFT\",\n",
    "\"S5MATR\",\n",
    "\"S5REAS\",\n",
    "\"S5UTIL\",\n",
    "\"\",\n",
    "\"IMV\",\n",
    "\"\",\n",
    "\"XJO\",\n",
    "\"\",\n",
    "\"BEL20\",\n",
    "\"SX5E\",\n",
    "\"SXXP\",\n",
    "\"\",\n",
    "\"IBOV\",\n",
    "\"IBXL\",\n",
    "\"IFIX\",\n",
    "\"\",\n",
    "\"TSX\",\n",
    "\"HSI\",\n",
    "\"399001\",\n",
    "\"\",\n",
    "\"OMXC25\",\n",
    "\"SXXP\",\n",
    "\"\",\n",
    "\"OMXH25\",\n",
    "\"SX5E\",\n",
    "\"SXXP\",\n",
    "\"\",\n",
    "\"PX1\",\n",
    "\"SX5E\",\n",
    "\"SXXP\",\n",
    "\"\",\n",
    "\"DAX\",\n",
    "\"MDAX\",\n",
    "\"SDXP\",\n",
    "\"SX5E\",\n",
    "\"SXXP\",\n",
    "\"TDXP\",\n",
    "\"\",\n",
    "\"OXMI10\",\n",
    "\"\",\n",
    "\"NIFTY\",\n",
    "\"BANKNIFTY\",\n",
    "\"SENSEX\",\n",
    "\"\",\n",
    "\"TA125\",\n",
    "\"TA35\",\n",
    "\"\",\n",
    "\"FTSEMIB\",\n",
    "\"SX5E\",\n",
    "\"SXXP\",\n",
    "\"\",\n",
    "\"OMXRGI\",\n",
    "\"OMXVGI\",\n",
    "\"\",\n",
    "\"AEX\",\n",
    "\"SX5E\",\n",
    "\"SXXP\",\n",
    "\"\",\n",
    "\"N250G\",\n",
    "\"SXXP\",\n",
    "\"SXXP\",\n",
    "\"PSI20\",\n",
    "\"SXXP\",\n",
    "\"\",\n",
    "\"MOEX10\",\n",
    "\"MOEXBMI\",\n",
    "\"MOEXCH\",\n",
    "\"MOEXCN\",\n",
    "\"MOEXEU\",\n",
    "\"MOEXFN\",\n",
    "\"MOEXINN\",\n",
    "\"MOEXMM\",\n",
    "\"IMOEX\",\n",
    "\"MCXSM\",\n",
    "\"MOEXTL\",\n",
    "\"MOEXTN\",\n",
    "\"RUBMI\",\n",
    "\"RTSCH\",\n",
    "\"RTSI\",\n",
    "\"\",\n",
    "\"STI\",\n",
    "    \"\", ]\n",
    "for i in test_index_list:\n",
    "    symbol_list_dow = ss.get_symbol_list(index=i, symbols_only=True)\n",
    "    print(i, symbol_list_dow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_all_tickers import get_tickers as gt\n",
    "\n",
    "list_of_tickers = gt.get_tickers(NYSE=True, NASDAQ=True, AMEX=False)\n",
    "len(list_of_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJIA\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m#This loop will iterate over ticker list, will pass one ticker to get data, and save that data as file.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mfor\u001b[39;00m tik \u001b[39min\u001b[39;00m ticker_list:\n\u001b[0;32m---> 34\u001b[0m     getData(tik)\n\u001b[1;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m11\u001b[39m):\n\u001b[1;32m     37\u001b[0m     \u001b[39mprint\u001b[39m(files[i])\n",
      "Cell \u001b[0;32mIn [6], line 23\u001b[0m, in \u001b[0;36mgetData\u001b[0;34m(ticker)\u001b[0m\n\u001b[1;32m     21\u001b[0m dataname \u001b[39m=\u001b[39m ticker \u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(today)\n\u001b[1;32m     22\u001b[0m files\u001b[39m.\u001b[39mappend(dataname)\n\u001b[0;32m---> 23\u001b[0m SaveData(data, dataname)\n",
      "Cell \u001b[0;32mIn [6], line 29\u001b[0m, in \u001b[0;36mSaveData\u001b[0;34m(df, filename)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mSaveData\u001b[39m(df, filename):\n\u001b[0;32m---> 29\u001b[0m     df\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39m./data /\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mfilename \u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3540\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3542\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3543\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3544\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3548\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3549\u001b[0m )\n\u001b[0;32m-> 3551\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3552\u001b[0m     path_or_buf,\n\u001b[1;32m   3553\u001b[0m     line_terminator\u001b[39m=\u001b[39;49mline_terminator,\n\u001b[1;32m   3554\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3555\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3556\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3557\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3558\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3559\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3560\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3561\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3562\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3563\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3564\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3565\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3566\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3567\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3568\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1162\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1163\u001b[0m     line_terminator\u001b[39m=\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1179\u001b[0m )\n\u001b[0;32m-> 1180\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1182\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1183\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[1;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[1;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[1;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:697\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[0;32m--> 697\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[1;32m    699\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    701\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:571\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    569\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[1;32m    570\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 571\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data '"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas_datareader import data as pdr\n",
    "from datetime import date\n",
    "import yfinance as yf\n",
    "yf.pdr_override()\n",
    "\n",
    "# Tickers list\n",
    "# We can add and delete any ticker from the list to get desired ticker live data\n",
    "ticker_list = ['DJIA', 'DOW', 'LB', 'EXPE', 'PXD', 'MCHP', 'CRM', 'JEC', 'NRG', 'HFC', 'NOW']\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# We can get data by our choice by giving days bracket\n",
    "start_date = \"2017-01-01\"\n",
    "end_date =\"2019-11-30\"\n",
    "\n",
    "files = []\n",
    "def getData(ticker):\n",
    "    print(ticker)\n",
    "    data = pdr.get_data_yahoo(ticker, start=start_date, end=today)\n",
    "    dataname = ticker +'_'+ str(today)\n",
    "    files.append(dataname)\n",
    "    SaveData(data, dataname)\n",
    "\n",
    "# Create a data folder in your current dir.\n",
    "\n",
    "\n",
    "def SaveData(df, filename):\n",
    "    df.to_csv('./data /'+filename +'.csv')\n",
    "\n",
    "#This loop will iterate over ticker list, will pass one ticker to get data, and save that data as file.\n",
    "\n",
    "for tik in ticker_list:\n",
    "    getData(tik)\n",
    "\n",
    "for i in range(0, 11):\n",
    "    print(files[i])\n",
    "    df1 = pd.read_csv('./data/'+ str(files[i]) +'.csv')\n",
    "    print(df1.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
